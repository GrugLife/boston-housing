{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boston Housing Dat\n",
    "\n",
    "In order to gain a better understanding of the metrics used in regression settings, I will be looking at the Boston Housing Dataset\n",
    "\n",
    "First use the cell below to read in the dataset and set up the training and testing data that will be used for the rest of the problem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# import models\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# import metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "boston = load_boston()\n",
    "y = boston.target\n",
    "X = boston.data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate each of the models you imported\n",
    "# For now use the defaults for all the hyperparameters\n",
    "\n",
    "# Decision Tree\n",
    "dt_mod = DecisionTreeRegressor()\n",
    "\n",
    "# Random Forest\n",
    "rf_mod = RandomForestRegressor()\n",
    "\n",
    "# Adaptive Boosting\n",
    "ada_mod = AdaBoostRegressor()\n",
    "\n",
    "# Linear Regression\n",
    "lm_mod = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit each of your models using the training data\n",
    "\n",
    "dt_mod.fit(X_train, y_train)\n",
    "\n",
    "rf_mod.fit(X_train, y_train)\n",
    "\n",
    "ada_mod.fit(X_train, y_train)\n",
    "\n",
    "lm_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test values for each model\n",
    "\n",
    "dt_pred = dt_mod.predict(X_test)\n",
    "\n",
    "rf_pred = rf_mod.predict(X_test)\n",
    "\n",
    "ada_pred = ada_mod.predict(X_test)\n",
    "\n",
    "lm_pred = lm_mod.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7252124886013344\n",
      "0.7252124886013344\n",
      "Since the above match, we can see that we have correctly calculated the r2 value.\n"
     ]
    }
   ],
   "source": [
    "def r2(actual, preds):\n",
    "    '''\n",
    "    INPUT:\n",
    "    actual - numpy array or pd series of actual y values\n",
    "    preds - numpy array or pd series of predicted y values\n",
    "    OUTPUT:\n",
    "    returns the r-squared score as a float\n",
    "    '''\n",
    "    sse = np.sum((actual-preds)**2)\n",
    "    sst = np.sum((actual-np.mean(actual))**2)\n",
    "    return 1 - sse/sst\n",
    "\n",
    "# Check solution matches sklearn\n",
    "print(r2(y_test, dt_pred))\n",
    "print(r2_score(y_test, dt_pred))\n",
    "print(\"Since the above match, we can see that we have correctly calculated the r2 value.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.795508982035926\n",
      "20.795508982035926\n",
      "If the above match, you are all set!\n"
     ]
    }
   ],
   "source": [
    "def mse(actual, preds):\n",
    "    '''\n",
    "    INPUT:\n",
    "    actual - numpy array or pd series of actual y values\n",
    "    preds - numpy array or pd series of predicted y values\n",
    "    OUTPUT:\n",
    "    returns the mean squared error as a float\n",
    "    '''\n",
    "    \n",
    "    return np.sum((actual-preds)**2)/len(actual)\n",
    "\n",
    "\n",
    "# Check your solution matches sklearn\n",
    "print(mse(y_test, dt_pred))\n",
    "print(mean_squared_error(y_test, dt_pred))\n",
    "print(\"If the above match, you are all set!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.18622754491018\n",
      "3.18622754491018\n",
      "If the above match, you are all set!\n"
     ]
    }
   ],
   "source": [
    "def mae(actual, preds):\n",
    "    '''\n",
    "    INPUT:\n",
    "    actual - numpy array or pd series of actual y values\n",
    "    preds - numpy array or pd series of predicted y values\n",
    "    OUTPUT:\n",
    "    returns the mean absolute error as a float\n",
    "    '''\n",
    "    \n",
    "    return np.sum(np.abs(actual-preds))/len(actual)\n",
    "\n",
    "# Check your solution matches sklearn\n",
    "print(mae(y_test, dt_pred))\n",
    "print(mean_absolute_error(y_test, dt_pred))\n",
    "print(\"If the above match, you are all set!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2\n",
      "DT :\t 0.7252124886013344\n",
      "MSE\n",
      "DT :\t 20.795508982035926\n",
      "MAE\n",
      "DT :\t 3.18622754491018\n",
      "\n",
      "\n",
      "R2\n",
      "RF :\t 0.8314785799182443\n",
      "MSE\n",
      "RF :\t 12.753449700598804\n",
      "MAE\n",
      "RF :\t 2.3514371257485034\n",
      "\n",
      "\n",
      "R2\n",
      "ADA :\t 0.799901633436377\n",
      "MSE\n",
      "ADA :\t 15.143145909304039\n",
      "MAE\n",
      "ADA :\t 2.6385133840517563\n",
      "\n",
      "\n",
      "R2\n",
      "lm :\t 0.7258515818230061\n",
      "MSE\n",
      "lm :\t 20.747143360308847\n",
      "MAE\n",
      "lm :\t 3.15128783658839\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n, preds in zip(['DT', 'RF', 'ADA', 'lm'],[dt_pred, rf_pred, ada_pred, lm_pred]):\n",
    "    print(\"R2\")\n",
    "    print(n,\":\\t\", r2(y_test, preds))\n",
    "    print('MSE')\n",
    "    print(n,\":\\t\", mse(y_test, preds))\n",
    "    print('MAE')\n",
    "    print(n,\":\\t\", mae(y_test, preds))\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
